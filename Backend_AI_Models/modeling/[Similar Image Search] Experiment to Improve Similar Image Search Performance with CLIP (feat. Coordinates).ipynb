{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0530bf62",
   "metadata": {},
   "source": [
    "# 필요 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "800708a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T03:54:08.226586Z",
     "start_time": "2024-04-09T03:53:58.331970Z"
    }
   },
   "outputs": [],
   "source": [
    "# 파이토치 및 토치비전 관련 라이브러리\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "\n",
    "# 이미지 처리를 위한 PIL 라이브러리\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel  # CLIP 모델 관련 라이브러리\n",
    "\n",
    "# 넘파이 및 랜덤 모듈\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 운영 체제 및 경로 검색 관련 모듈\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# 진행 상황을 시각화하기 위한 tqdm 모듈\n",
    "from tqdm import tqdm\n",
    "\n",
    "# chromadb 및 모델성능평가 관련 모듈\n",
    "import chromadb\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# 시각화 관련 모듈\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import warnings\n",
    "\n",
    "# 모든 경고를 무시합니다.\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f3938e",
   "metadata": {},
   "source": [
    "# 데이터 전처리 및 벡터DB구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc2123b",
   "metadata": {},
   "source": [
    "## 마스킹 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83aa18c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T03:54:54.501151Z",
     "start_time": "2024-04-09T03:54:54.487972Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_and_mask_image(image_path, confidence_threshold=0.5):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "    \n",
    "    mask_model = maskrcnn_resnet50_fpn(pretrained=True).eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = mask_model(input_tensor)\n",
    "    \n",
    "    masks = prediction[0]['masks']\n",
    "    labels = prediction[0]['labels']\n",
    "    scores = prediction[0]['scores']\n",
    "    np_image = np.array(image)\n",
    "    \n",
    "    for i in range(len(scores)):\n",
    "        if scores[i] > confidence_threshold and labels[i].item() == 1:\n",
    "            mask = masks[i, 0]\n",
    "            np_image[mask > 0.5] = [0, 0, 0]\n",
    "    \n",
    "    return Image.fromarray(np_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7848eb1f",
   "metadata": {},
   "source": [
    "## CLIP 기반 벡터라이저 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f7a304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T03:55:05.269250Z",
     "start_time": "2024-04-09T03:55:05.264698Z"
    }
   },
   "outputs": [],
   "source": [
    "def vectorizor(image_path, mask_people=False, confidence_threshold=0.5):\n",
    "    if mask_people:\n",
    "        image = preprocess_and_mask_image(image_path, confidence_threshold)\n",
    "    else:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    \n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.get_image_features(**inputs)\n",
    "    \n",
    "    vector = image_features.detach().cpu().numpy().squeeze()\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a863b70",
   "metadata": {},
   "source": [
    "## 벡터DB시각화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c856ad58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T03:55:15.983037Z",
     "start_time": "2024-04-09T03:55:15.964461Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_embeddings_with_plotly(embeddings_list, metadatas):\n",
    "    embeddings_array = np.array(embeddings_list)\n",
    "    labels = [metadata['label'] for metadata in metadatas]\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    embeddings_reduced = pca.fit_transform(embeddings_array)\n",
    "\n",
    "    unique_labels = list(set(labels))\n",
    "    color_values = np.linspace(0, 1, len(unique_labels))\n",
    "    colors = ['rgba(' + ', '.join([f'{int(x*255)}' for x in plt.cm.rainbow(c)[:3]]) + ', 0.8)' for c in color_values]\n",
    "    label_to_color = {label: color for label, color in zip(unique_labels, colors)}\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for label in unique_labels:\n",
    "        idx = [i for i, l in enumerate(labels) if l == label]\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=embeddings_reduced[idx, 0],\n",
    "            y=embeddings_reduced[idx, 1],\n",
    "            z=embeddings_reduced[idx, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(size=5, color=label_to_color[label], opacity=0.8),\n",
    "            name=label\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(margin=dict(l=0, r=0, b=0, t=0), scene=dict(\n",
    "        xaxis_title='PCA 1',\n",
    "        yaxis_title='PCA 2',\n",
    "        zaxis_title='PCA 3'\n",
    "    ))\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be385b40",
   "metadata": {},
   "source": [
    "## 데이터셋 벡터DB화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d53427",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T03:55:32.630910Z",
     "start_time": "2024-04-09T03:55:32.619889Z"
    }
   },
   "outputs": [],
   "source": [
    "def images_to_vector_db(image_directory, db_path, collection_name, mask_people=False):\n",
    "    # 데이터베이스 클라이언트 생성\n",
    "    client = chromadb.PersistentClient(path=db_path)\n",
    "\n",
    "    # 기존 컬렉션 이름 리스트 생성\n",
    "    existing_collection_names = [col.name for col in client.list_collections()]\n",
    "\n",
    "    # 요청한 컬렉션 이름이 이미 존재하는지 확인\n",
    "    if collection_name in existing_collection_names:\n",
    "        # 이미 존재하는 경우 해당 컬렉션을 가져옴\n",
    "        collection = client.get_collection(collection_name)\n",
    "        print(\"Found existing collection, using it.\")\n",
    "    else:\n",
    "        # 존재하지 않는 경우 새로운 컬렉션 생성\n",
    "        collection = client.create_collection(collection_name)\n",
    "        print(\"Created new collection.\")\n",
    "\n",
    "    # 이미지 파일 경로 리스트 생성\n",
    "    img_list = sorted(glob(os.path.join(image_directory, \"*/*.jpg\")))\n",
    "    \n",
    "    # Embedding, Metadata 및 ID를 저장할 리스트 초기화\n",
    "    embeddings = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "    \n",
    "    # 이미지 처리 및 Embedding 생성 반복\n",
    "    for i, img_path in enumerate(tqdm(img_list, desc=\"Processing images\")):\n",
    "        # 이미지 파일의 레이블 및 파일 이름 추출\n",
    "        label_name = os.path.basename(os.path.dirname(img_path))\n",
    "        file_name = os.path.basename(img_path)\n",
    "        \n",
    "        # 이미지의 Embedding 생성\n",
    "        embedding = vectorizor(img_path, mask_people=mask_people)\n",
    "        \n",
    "        # Embedding, Metadata 및 ID를 리스트에 추가\n",
    "        embeddings.append(embedding)\n",
    "        metadatas.append({\n",
    "            \"uri\": img_path,\n",
    "            \"label\": label_name,\n",
    "            \"file_name\": file_name\n",
    "        })\n",
    "        \n",
    "        # 이미지 인덱스를 ID로 사용\n",
    "        ids.append(str(i))\n",
    "    \n",
    "    # Embedding을 리스트로 변환\n",
    "    embeddings_list = [embedding.tolist() for embedding in embeddings]\n",
    "    \n",
    "    # 데이터베이스에 데이터 추가\n",
    "    collection.add(\n",
    "        embeddings=embeddings_list,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids,\n",
    "    )\n",
    "    \n",
    "    print(\"Data upload completed!\")\n",
    "    \n",
    "    # 벡터DB 시각화\n",
    "    visualize_embeddings_with_plotly(embeddings_list, metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7704366",
   "metadata": {},
   "source": [
    "# 제주지역 이미지 벡터 데이터 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b477e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T03:57:25.642112Z",
     "start_time": "2024-04-09T03:57:24.969177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected IDs to be a non-empty list, got []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 마스킹을 적용하지 않은 벡터 DB 생성\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mimages_to_vector_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/travel_imgs/jeju\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/jeju_vector_db\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjeju_vector\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmask_people\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 50\u001b[0m, in \u001b[0;36mimages_to_vector_db\u001b[1;34m(image_directory, db_path, collection_name, mask_people)\u001b[0m\n\u001b[0;32m     47\u001b[0m embeddings_list \u001b[38;5;241m=\u001b[39m [embedding\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m embeddings]\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# 데이터베이스에 데이터 추가\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData upload completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# 벡터DB 시각화\u001b[39;00m\n",
      "File \u001b[1;32mE:\\ProgramData\\anaconda3\\envs\\torch_env\\lib\\site-packages\\chromadb\\api\\models\\Collection.py:146\u001b[0m, in \u001b[0;36mCollection.add\u001b[1;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd\u001b[39m(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    106\u001b[0m     ids: OneOrMany[ID],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m     uris: Optional[OneOrMany[URI]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    117\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add embeddings to the data store.\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m        ids: The ids of the embeddings you wish to add\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     (\n\u001b[0;32m    140\u001b[0m         ids,\n\u001b[0;32m    141\u001b[0m         embeddings,\n\u001b[0;32m    142\u001b[0m         metadatas,\n\u001b[0;32m    143\u001b[0m         documents,\n\u001b[0;32m    144\u001b[0m         images,\n\u001b[0;32m    145\u001b[0m         uris,\n\u001b[1;32m--> 146\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_embedding_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muris\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# We need to compute the embeddings if they're not provided\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;66;03m# At this point, we know that one of documents or images are provided from the validation above\u001b[39;00m\n",
      "File \u001b[1;32mE:\\ProgramData\\anaconda3\\envs\\torch_env\\lib\\site-packages\\chromadb\\api\\models\\Collection.py:545\u001b[0m, in \u001b[0;36mCollection._validate_embedding_set\u001b[1;34m(self, ids, embeddings, metadatas, documents, images, uris, require_embeddings_or_data)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_embedding_set\u001b[39m(\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    525\u001b[0m     ids: OneOrMany[ID],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    543\u001b[0m     Optional[URIs],\n\u001b[0;32m    544\u001b[0m ]:\n\u001b[1;32m--> 545\u001b[0m     valid_ids \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_cast_one_to_many_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    546\u001b[0m     valid_embeddings \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    547\u001b[0m         validate_embeddings(\n\u001b[0;32m    548\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_embeddings(maybe_cast_one_to_many_embedding(embeddings))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     )\n\u001b[0;32m    553\u001b[0m     valid_metadatas \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    554\u001b[0m         validate_metadatas(maybe_cast_one_to_many_metadata(metadatas))\n\u001b[0;32m    555\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m metadatas \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    556\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    557\u001b[0m     )\n",
      "File \u001b[1;32mE:\\ProgramData\\anaconda3\\envs\\torch_env\\lib\\site-packages\\chromadb\\api\\types.py:213\u001b[0m, in \u001b[0;36mvalidate_ids\u001b[1;34m(ids)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected IDs to be a list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mids\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected IDs to be a non-empty list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mids\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    215\u001b[0m dups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: Expected IDs to be a non-empty list, got []"
     ]
    }
   ],
   "source": [
    "# 마스킹 적용한 벡터 생성\n",
    "images_to_vector_db(image_directory='data/travel_imgs/jeju',\n",
    "                    db_path='./data/jeju_vector_db',\n",
    "                    collection_name='jeju_vector',\n",
    "                    mask_people=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf46905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.458px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
